{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pymatgen as mg\n",
    "import pymatgen.analysis.diffraction as anadi\n",
    "import pymatgen.analysis.diffraction.xrd as xrd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "patt_xrd = xrd.XRDCalculator('CuKa')\n",
    "\n",
    "train_path='/home/hjj/Desktop/GANsurface/train/'\n",
    "\n",
    "test_path='/home/hjj/Desktop/GANsurface/test/'\n",
    "\n",
    "global sample_num, rmat_num, series_num\n",
    "sample_num=1 #output of G\n",
    "rmat_num=28  #row nums of the matrix for the input of CNN \n",
    "series_num=3\n",
    "#input of D\n",
    "global A\n",
    "A =12.8282906600000004**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNet, self).__init__()\n",
    "        self.Dlstm=nn.LSTM(\n",
    "            input_size=series_num,\n",
    "            hidden_size=32,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(32,10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10,1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        #nn.Linear(32,1)\n",
    "        #nn.Relu\n",
    "        #nn.Linear\n",
    "        #nn.Sigmoid\n",
    "        \n",
    "    def forward(self,x):\n",
    "        D_out,(h_n,h_c)=self.Dlstm(x,None)\n",
    "        out = self.out(D_out[:,-1,:]) #(batch,time step,input)   \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slab_energy(folder):\n",
    "    energy_string=os.popen('grep TOTEN '+folder+'/OUTCAR | tail -1').read().split(' ')[-2]\n",
    "    energy_slab=round(np.float64(float(energy_string)),5)\n",
    "    return energy_slab\n",
    "def get_bluk_energy(folder):\n",
    "    energy_string=os.popen('grep TOTEN '+folder+'/OUTCAR_bulk | tail -1').read().split(' ')[-2]\n",
    "    energy_bluk=round(np.float64(float(energy_string)),5)\n",
    "    return energy_bluk\n",
    "\n",
    "\n",
    "def get_cpx222_surface_energy(folder):\n",
    "    slab=get_slab_energy(folder)\n",
    "    bluk=get_bluk_energy(folder)\n",
    "    \n",
    "    global A\n",
    "    sur_e= (slab-bluk)/(2*A)\n",
    "    return sur_e\n",
    "\n",
    "def linear_transform(energy):\n",
    "    global extend_num, move_num\n",
    "    energy_transform=(energy-move_num)*extend_num\n",
    "    return energy_transform\n",
    "def inverse_transform(energy_transform):\n",
    "    global extend_num, move_num\n",
    "    energy=energy_transform/extend_num+move_num\n",
    "    return energy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global extend_num, move_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_num=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13767811697355392\n"
     ]
    }
   ],
   "source": [
    "move_num=get_cpx222_surface_energy('/home/hjj/Desktop/GANsurface/train/00000')\n",
    "print(move_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hjj/anaconda3/envs/tensorflow/lib/python3.6/site-packages/pymatgen/io/cif.py:44: UserWarning: Please install optional dependency pybtex if youwant to extract references from CIF files.\n",
      "  warnings.warn(\"Please install optional dependency pybtex if you\"\n"
     ]
    }
   ],
   "source": [
    "base=mg.Structure.from_file(train_path+'00000/POSCAR')\n",
    "base_xrd =patt_xrd.get_pattern(base)\n",
    "base_x=[]\n",
    "base_y=[]\n",
    "for i in range(len(base_xrd.y)):\n",
    "    if base_xrd.y[i] >0.0001 and base_xrd.y[i] < 1:\n",
    "        base_y.append(base_xrd.y[i])\n",
    "        base_x.append(base_xrd.x[i])\n",
    "base_x=base_x[:28]\n",
    "base_y=base_y[:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_xxpsk(file_path):\n",
    "    folder=np.random.choice(glob.glob(file_path +\"*\"))\n",
    "    #pos_name=folder+'/POSCAR'\n",
    "    #out_name=folder+'/OUTCAR'\n",
    "    return folder\n",
    "\n",
    "def tomgStructure(folder):\n",
    "    POSfile=folder+'/POSCAR'      \n",
    "    R_mgS=mg.Structure.from_file(POSfile)\n",
    "    return R_mgS\n",
    "\n",
    "###\n",
    "##input_data_to_model\n",
    "###\n",
    "\n",
    "def get_xrdmat_slab(mgStructure):\n",
    "    global rmat_num\n",
    "    xrd_data4 =patt_xrd.get_pattern(mgStructure)\n",
    "\n",
    "    i_column = 28\n",
    "    xxx=[]\n",
    "    yyy=[]\n",
    "    mat4=[]\n",
    "    xrd_i=len(xrd_data4)\n",
    "    for i in range(xrd_i):\n",
    "        if xrd_data4.y[i] >0.0001 and xrd_data4.y[i] < 1:\n",
    "            xxx.append(xrd_data4.x[i])\n",
    "            yyy.append(xrd_data4.y[i])\n",
    "    mat4.append(np.asarray(xxx))\n",
    "    mat4.append(np.asarray(yyy))\n",
    "    mat4=np.asarray(mat4)\n",
    "    \n",
    "    xrd_x=[]\n",
    "    xrd_y=[]\n",
    "    xrd_mat4=[]\n",
    "    xrow=len(mat4[0])\n",
    "    \n",
    "    if xrow < i_column:\n",
    "        for i in mat4[0]:\n",
    "            xrd_x.append(i)\n",
    "        for j in mat4[1]:\n",
    "            xrd_y.append(j)\n",
    "        for i in range(0,i_column-xrow):\n",
    "            xrd_x.append(0)\n",
    "            xrd_y.append(0)\n",
    "        xrd_x=np.asarray(xrd_x)\n",
    "        xrd_y=np.asarray(xrd_y)\n",
    "    if xrow > i_column:\n",
    "        xrd_x=mat4[0][:i_column]\n",
    "        xrd_y=mat4[1][:i_column]\n",
    "    if xrow == i_column:\n",
    "        xrd_x= mat4[0]\n",
    "        xrd_y= mat4[1]\n",
    "        \n",
    "    #xrd_x=xrd_x-base_x\n",
    "    xrd_y=1000*(xrd_y-base_y)\n",
    "    \n",
    "    xrd_x=np.sin(np.dot(1/180*np.pi,xrd_x))\n",
    "    xrd_y=(np.arctan(xrd_y))/180*np.pi\n",
    "    xrd_mat4.append(xrd_x)\n",
    "    xrd_mat4.append(xrd_y)\n",
    "    xrd_mat4=np.array(xrd_mat4)\n",
    "    return xrd_mat4\n",
    "\n",
    "###\n",
    "##input_data_as_knowlegde\n",
    "###\n",
    "'''\n",
    "def get_Gibbs(folder):\n",
    "    energy_string=os.popen('grep TOTEN '+folder+'/OUTCAR | tail -1').read().split(' ')[-2]\n",
    "    Gibbs=np.float64(float(energy_string))\n",
    "    Gibbs=round(Gibbs,6)\n",
    "    return Gibbs\n",
    "'''\n",
    "##\n",
    "###\n",
    "def get_atoms_num(folder2):\n",
    "    xxx=tomgStructure(folder2)\n",
    "    anum=len(xxx.sites)\n",
    "    return anum\n",
    "\n",
    "\n",
    "###\n",
    "##input_data_for_G\n",
    "###\n",
    "def GANs_Gmat(Random_Structure):\n",
    "    global rmat_num\n",
    "    RS_xrdmat = get_xrdmat_slab(Random_Structure)\n",
    "    multimat3_RS =  np.zeros((rmat_num,rmat_num),dtype='float32')\n",
    "    multimat3_RS = np.asarray((np.dot(RS_xrdmat.T, RS_xrdmat)))\n",
    "    return multimat3_RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size=(sample_num,28,28)):\n",
    "        super(GNet, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(#(3,28,28)\n",
    "                in_channels=sample_num,\n",
    "                out_channels=32,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),#->(32,28,28)\n",
    "            nn.ReLU(),#->(32,28,28)\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )#->(#->(32,14,14))\n",
    "        self.conv2=nn.Sequential(#->(32,14,14))\n",
    "            nn.Conv2d(\n",
    "                in_channels=32,\n",
    "                out_channels=64,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "                padding=2,\n",
    "            ),#->(64,14,14)\n",
    "            nn.ReLU(),#->(64,14,14)\n",
    "            nn.MaxPool2d(kernel_size=2),#->(64,7,7)\n",
    "        )\n",
    "        self.out=nn.Sequential(\n",
    "            nn.Linear(64*7*7,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,sample_num),            \n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x) #batch(64,7,7)\n",
    "        x=x.view(x.size(0),-1) #(batch, 64*7*7)\n",
    "        output=torch.unsqueeze(self.out(x),dim=0)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "G1=GNet()\n",
    "D1=DNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_D1=torch.optim.Adam(D1.parameters(),lr=0.1)\n",
    "opt_G1=torch.optim.Adam(G1.parameters(),lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_series=[]\n",
    "for i in range(series_num):\n",
    "    path_s=random_xxpsk(train_path)\n",
    "    ee1=get_cpx222_surface_energy(path_s)\n",
    "    ee1=linear_transform(ee1)\n",
    "    train_series.append(ee1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_Gl=[]    \n",
    "mat_Dl=[]\n",
    "pre_dd=[]\n",
    "pre_gg=[]\n",
    "error_test=[]\n",
    "error_train=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 20.0 12.82829066 12.82829066\n",
       " angles : 90.0 90.0 90.0\n",
       " volume : 3291.3008251488645\n",
       "      A : 20.0 0.0 0.0\n",
       "      B : 0.0 12.82829066 0.0\n",
       "      C : 0.0 0.0 12.82829066\n",
       "PeriodicSite: Cs (3.2071, 3.2071, 3.2071) [0.1604, 0.2500, 0.2500]\n",
       "PeriodicSite: Cs (9.6212, 3.2071, 3.2071) [0.4811, 0.2500, 0.2500]\n",
       "PeriodicSite: Cs (3.2071, 9.6212, 3.2071) [0.1604, 0.7500, 0.2500]\n",
       "PeriodicSite: Cs (9.6212, 9.6212, 3.2071) [0.4811, 0.7500, 0.2500]\n",
       "PeriodicSite: Cs (3.2071, 3.2071, 9.6212) [0.1604, 0.2500, 0.7500]\n",
       "PeriodicSite: Cs (9.6212, 3.2071, 9.6212) [0.4811, 0.2500, 0.7500]\n",
       "PeriodicSite: Cs (3.2071, 9.6212, 9.6212) [0.1604, 0.7500, 0.7500]\n",
       "PeriodicSite: Cs (9.6212, 9.6212, 9.6212) [0.4811, 0.7500, 0.7500]\n",
       "PeriodicSite: Pb (0.0000, 0.0000, 0.0000) [0.0000, 0.0000, 0.0000]\n",
       "PeriodicSite: Pb (6.4141, 0.0000, 0.0000) [0.3207, 0.0000, 0.0000]\n",
       "PeriodicSite: Pb (0.0000, 6.4141, 0.0000) [0.0000, 0.5000, 0.0000]\n",
       "PeriodicSite: Pb (6.4141, 6.4141, 0.0000) [0.3207, 0.5000, 0.0000]\n",
       "PeriodicSite: Pb (0.0000, 0.0000, 6.4141) [0.0000, 0.0000, 0.5000]\n",
       "PeriodicSite: Pb (6.4141, 0.0000, 6.4141) [0.3207, 0.0000, 0.5000]\n",
       "PeriodicSite: Pb (0.0000, 6.4141, 6.4141) [0.0000, 0.5000, 0.5000]\n",
       "PeriodicSite: Pb (6.4141, 6.4141, 6.4141) [0.3207, 0.5000, 0.5000]\n",
       "PeriodicSite: Br (0.0000, 0.0000, 3.2071) [0.0000, 0.0000, 0.2500]\n",
       "PeriodicSite: Br (0.0000, 3.2071, 0.0000) [0.0000, 0.2500, 0.0000]\n",
       "PeriodicSite: Br (3.2071, 0.0000, 0.0000) [0.1604, 0.0000, 0.0000]\n",
       "PeriodicSite: Br (6.4141, 0.0000, 3.2071) [0.3207, 0.0000, 0.2500]\n",
       "PeriodicSite: Br (6.4141, 3.2071, 0.0000) [0.3207, 0.2500, 0.0000]\n",
       "PeriodicSite: Br (9.6212, 0.0000, 0.0000) [0.4811, 0.0000, 0.0000]\n",
       "PeriodicSite: Br (0.0000, 6.4141, 3.2071) [0.0000, 0.5000, 0.2500]\n",
       "PeriodicSite: Br (0.0000, 9.6212, 0.0000) [0.0000, 0.7500, 0.0000]\n",
       "PeriodicSite: Br (3.2071, 6.4141, 0.0000) [0.1604, 0.5000, 0.0000]\n",
       "PeriodicSite: Br (6.4141, 6.4141, 3.2071) [0.3207, 0.5000, 0.2500]\n",
       "PeriodicSite: Br (6.4141, 9.6212, 0.0000) [0.3207, 0.7500, 0.0000]\n",
       "PeriodicSite: Br (9.6212, 6.4141, 0.0000) [0.4811, 0.5000, 0.0000]\n",
       "PeriodicSite: Br (0.0000, 0.0000, 9.6212) [0.0000, 0.0000, 0.7500]\n",
       "PeriodicSite: Br (0.0000, 3.2071, 6.4141) [0.0000, 0.2500, 0.5000]\n",
       "PeriodicSite: Br (3.2071, 0.0000, 6.4141) [0.1604, 0.0000, 0.5000]\n",
       "PeriodicSite: Br (6.4141, 0.0000, 9.6212) [0.3207, 0.0000, 0.7500]\n",
       "PeriodicSite: Br (6.4141, 3.2071, 6.4141) [0.3207, 0.2500, 0.5000]\n",
       "PeriodicSite: Br (9.6212, 0.0000, 6.4141) [0.4811, 0.0000, 0.5000]\n",
       "PeriodicSite: Br (3.2071, 6.4141, 6.4141) [0.1604, 0.5000, 0.5000]\n",
       "PeriodicSite: I (0.0000, 6.4141, 9.6212) [0.0000, 0.5000, 0.7500]\n",
       "PeriodicSite: I (0.0000, 9.6212, 6.4141) [0.0000, 0.7500, 0.5000]\n",
       "PeriodicSite: I (6.4141, 6.4141, 9.6212) [0.3207, 0.5000, 0.7500]\n",
       "PeriodicSite: I (6.4141, 9.6212, 6.4141) [0.3207, 0.7500, 0.5000]\n",
       "PeriodicSite: I (9.6212, 6.4141, 6.4141) [0.4811, 0.5000, 0.5000]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mg.Structure.from_file('/home/hjj/Desktop/GANsurface/train/00002/POSCAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "error:  4.2217416058948354e-05\n",
      "1.3927538739308805\n",
      "-0.7787715318105286\n",
      "0.5411913628227828\n",
      "0.5410305054522705\n",
      "2\n",
      "error:  7.62149999999906e-05\n",
      "1.4352700865751458\n",
      "-0.5364981776481704\n",
      "0.40706927103157936\n",
      "0.41520748954505715\n",
      "3\n",
      "error:  4.2217416058948354e-05\n",
      "1.3918966670297364\n",
      "-0.7304271308221303\n",
      "0.5160923605481456\n",
      "0.5182968041392688\n",
      "----------------------------------test-------------------------\n",
      "/home/hjj/Desktop/GANsurface/test/00047\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tt_energy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-2fa8b3e07bb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath1_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0mtt_energy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt_energy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DFT'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtt_energy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mE_Gibbs_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt_energy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tt_energy' is not defined"
     ]
    }
   ],
   "source": [
    "file_path=train_path\n",
    "tfset=[]\n",
    "for step in range(1,4):       \n",
    " \n",
    "    sample_path=[]\n",
    "    for i in range(1,sample_num + 1):\n",
    "        path_ = random_xxpsk(file_path)\n",
    "        sample_path.append(path_)\n",
    "        tfset.append(path_)\n",
    "    E_Gibbs=0\n",
    "    for path1_ in sample_path:\n",
    "        try:\n",
    "            total_energy=get_cpx222_surface_energy(path1_)\n",
    "            E_Gibbs=linear_transform(total_energy)\n",
    "            #print(samp_Gibbs)\n",
    "        except:\n",
    "            print(path1_)\n",
    "         \n",
    "        train_series.pop(-1)\n",
    "        train_series.append(E_Gibbs)\n",
    "        \n",
    "        \n",
    "    input_series_D=np.asarray(train_series,dtype=np.float64)       \n",
    "    input_series_D=Variable(torch.from_numpy(input_series_D[np.newaxis,np.newaxis,:]),requires_grad=True)\n",
    "    \n",
    "    prob_Tfactor_mat0=D1(input_series_D)\n",
    "    pre_dd.append(prob_Tfactor_mat0.data.numpy().mean())\n",
    "    \n",
    "    g_in=[]\n",
    "    for path2_ in sample_path:\n",
    "        path2_=str(path2_)                \n",
    "        \n",
    "        try:\n",
    "            tomgS=tomgStructure(path2_)\n",
    "            #print(tomgS)\n",
    "            gin=GANs_Gmat(tomgS)\n",
    "            \n",
    "            #print(gin)\n",
    "        except:\n",
    "            pass\n",
    "        g_in.append(gin)\n",
    "       \n",
    "    g_in=np.asarray(g_in)\n",
    "    g_in=g_in[np.newaxis,:,:,:] \n",
    "    g_in=np.asarray(g_in,dtype=np.float64) \n",
    "    g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "    \n",
    "    Gout=G1(g_in)\n",
    "    Gout=round(Gout.data.numpy().mean(),6)\n",
    "    train_series.append(Gout)\n",
    "    train_series.pop(0)\n",
    "        \n",
    "    input_series_D=np.asarray(train_series,dtype=np.float64)       \n",
    "    input_series_D=Variable(torch.from_numpy(input_series_D[np.newaxis,np.newaxis,:]),requires_grad=True)\n",
    "    \n",
    "    \n",
    "    prob_G1_mat1=D1(input_series_D)\n",
    "    pre_gg.append(prob_G1_mat1.data.numpy().mean())\n",
    "    \n",
    "    D1_loss=-torch.mean(torch.log(prob_Tfactor_mat0)+torch.log(1.-prob_G1_mat1))\n",
    "    dd=D1_loss.data.numpy().mean()\n",
    "    mat_Dl.append(dd)\n",
    "    \n",
    "    G1_loss=torch.mean(torch.log(1.-prob_G1_mat1))\n",
    "    gg=G1_loss.data.numpy().mean()\n",
    "    mat_Gl.append(gg)\n",
    "    \n",
    "    if step%3==0:\n",
    "        opt_D1.zero_grad()\n",
    "        D1_loss.backward(retain_graph=True)\n",
    "        opt_D1.step()\n",
    "        \n",
    "        opt_G1.zero_grad()\n",
    "        G1_loss.backward()\n",
    "        opt_G1.step()\n",
    "    else:\n",
    "        opt_D1.zero_grad()\n",
    "        D1_loss.backward()\n",
    "        opt_D1.step()\n",
    "    \n",
    "\n",
    "\n",
    "    if step%1==0:\n",
    "        print(step)\n",
    "        print('error: ',abs(inverse_transform(Gout)-inverse_transform(E_Gibbs)))\n",
    "        \n",
    "        print(dd)\n",
    "        print(gg)\n",
    "        print(prob_Tfactor_mat0.data.numpy().mean())\n",
    "        print(prob_G1_mat1.data.numpy().mean())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    if step%3==0:\n",
    "        print('----------------------------------test-------------------------')\n",
    "        file_path_test=test_path\n",
    "        E_Gibbs_1=[]\n",
    "        E_Gmodel_1=[]\n",
    "        for step_test in range(10):\n",
    "            sample_path=[]\n",
    "            for i in range(1,sample_num + 1):\n",
    "                path_ = random_xxpsk(file_path_test)\n",
    "                sample_path.append(path_)\n",
    "            \n",
    "            for path1_ in sample_path:\n",
    "                try:\n",
    "                    total_energy=get_cpx222_surface_energy(path1_)\n",
    "                    tt_energy=linear_transform(total_energy)\n",
    "            #print(samp_Gibbs)\n",
    "                except:\n",
    "                    print(path1_)\n",
    "                    \n",
    "            tt_energy=inverse_transform(float(tt_energy))\n",
    "            print('DFT',tt_energy)\n",
    "            E_Gibbs_1.append(tt_energy)\n",
    "        \n",
    "                   \n",
    "\n",
    "        #print(tfactor.shape)\n",
    "    \n",
    "            g_in=[]\n",
    "            for path2_ in sample_path:\n",
    "                path2_=str(path2_)                \n",
    "        \n",
    "                try:\n",
    "                    tomgS=tomgStructure(path2_)\n",
    "            #print(tomgS)\n",
    "                    gin=GANs_Gmat(tomgS)\n",
    "                    \n",
    "            #print(gin)\n",
    "                except:\n",
    "                    pass\n",
    "                g_in.append(gin)\n",
    "       \n",
    "            g_in=np.asarray(g_in)\n",
    "            g_in=g_in[np.newaxis,:,:,:] \n",
    "            g_in=np.asarray(g_in,dtype=np.float64) \n",
    "            g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "    \n",
    "            Gout=G1(g_in)\n",
    "        \n",
    "        #print(Gout.shape)\n",
    "    \n",
    "            G_data=round(inverse_transform(Gout.data.numpy().mean()),6)\n",
    "            print('G_predict',G_data)\n",
    "            E_Gmodel_1.append(G_data)\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "            print('error',abs(tt_energy-G_data))\n",
    "            \n",
    "        print('------------------end-test----------------------------')\n",
    "        xxx=abs(abs(np.asarray(E_Gibbs_1))-abs(np.asarray(E_Gmodel_1))).mean()\n",
    "        print(xxx)\n",
    "        error_test.append(xxx)\n",
    "        \n",
    "        X=np.asarray(E_Gibbs_1)\n",
    "        Y=np.asarray(E_Gmodel_1)\n",
    "\n",
    "        xbar=X.mean()\n",
    "        ybar=Y.mean()\n",
    "        SSR=0\n",
    "        varX=0\n",
    "        varY=0\n",
    "        for i in range(len(X)):\n",
    "            diffxxbar=X[i]-xbar\n",
    "            diffyybar=Y[i]-ybar\n",
    "            SSR+=(diffxxbar*diffyybar)\n",
    "            varX+=diffxxbar**2\n",
    "            varY+=diffyybar**2\n",
    "    \n",
    "        SST=math.sqrt(varX+varY)\n",
    "        R2=(SSR/SST)**2\n",
    "        print(\"R2:\",R2)\n",
    "        #r2.append(R2)\n",
    "    else:\n",
    "        pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1818.6451070308685\n"
     ]
    }
   ],
   "source": [
    "\n",
    "E_Gibbs_test=[]\n",
    "E_Gmodel_test=[]\n",
    "abserrset=[]\n",
    "MSEset=[]\n",
    "err0set=[]\n",
    "testfile=[]\n",
    "for m1,n1,fname in os.walk(test_path):\n",
    "    for ieach in n1:\n",
    "        ieach=test_path+ieach\n",
    "        testfile.append(ieach)\n",
    "start=time.time()        \n",
    "for path_ in testfile:\n",
    "    try:\n",
    "        GGG=get_cpx222_surface_energy(path_)\n",
    "        #GGG=inverse_transform(GGG)\n",
    "        E_Gibbs_test.append(GGG)\n",
    "        \n",
    "        g_in=[]\n",
    "        tomgS=tomgStructure(path_)\n",
    "        gin=GANs_Gmat(tomgS)\n",
    "        g_in.append(gin)\n",
    "        g_in=np.asarray(g_in)\n",
    "        g_in=g_in[np.newaxis,:,:,:]\n",
    "        g_in=np.asarray(g_in,dtype=np.float64)\n",
    "        g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "        Gout=G1(g_in)\n",
    "        G_data=Gout.data.numpy().mean()\n",
    "        G_data=inverse_transform(G_data)\n",
    "        #G_data=get_energy_per_atom(G_data)\n",
    "        E_Gmodel_test.append(G_data)\n",
    "        #print(G_data)\n",
    "        #print(GGG)\n",
    "        abserr=abs(G_data-GGG)\n",
    "        mse=(G_data-GGG)**2\n",
    "        abserrset.append(abserr)\n",
    "        MSEset.append(mse)\n",
    "        err0=abs(abserr/GGG)\n",
    "        err0set.append(err0)\n",
    "    except:\n",
    "        print(path_)\n",
    "end=time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00011977779882471464\n",
      "2.1182996616444365e-08\n",
      "0.000145543796214213\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(abserrset).mean())\n",
    "\n",
    "print(np.asarray(MSEset).mean())\n",
    "\n",
    "print(np.sqrt(np.asarray(MSEset).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abserrset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_Gibbs_t=[]\n",
    "E_Gmodel_t=[]\n",
    "abs_t_errset=[]\n",
    "err_t_0set=[]\n",
    "tMSEset=[]\n",
    "testfile=[]\n",
    "for m1,n1,fname in os.walk(train_path):\n",
    "    for ieach in n1:\n",
    "        ieach=train_path+ieach\n",
    "        testfile.append(ieach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#'''        \n",
    "for path_ in testfile:\n",
    "    try:\n",
    "        GGG=get_cpx222_surface_energy(path_)\n",
    "        \n",
    "        #GGG=get_energy_per_atom(GGG)\n",
    "        E_Gibbs_t.append(GGG)\n",
    "        g_in=[]\n",
    "        tomgS=tomgStructure(path_)\n",
    "        gin=GANs_Gmat(tomgS)\n",
    "        g_in.append(gin)\n",
    "        g_in=np.asarray(g_in)\n",
    "        g_in=g_in[np.newaxis,:,:,:]\n",
    "        g_in=np.asarray(g_in,dtype=np.float64)\n",
    "        g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "        Gout=G1(g_in)\n",
    "        G_data=Gout.data.numpy().mean()\n",
    "        G_data=inverse_transform(G_data)\n",
    "        #G_data=get_energy_per_atom(G_data)\n",
    "        E_Gmodel_t.append(G_data)\n",
    "        #print(G_data)\n",
    "        #print(GGG)\n",
    "        abserr=abs(G_data-GGG)\n",
    "        tmse=(G_data-GGG)**2\n",
    "        tMSEset.append(tmse)\n",
    "        abs_t_errset.append(abserr)\n",
    "        err0=abs(abserr/GGG)\n",
    "        err_t_0set.append(err0)\n",
    "    except:\n",
    "        print(path_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.909317651984659e-05\n",
      "5.161632932457264e-09\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(abs_t_errset).mean())\n",
    "\n",
    "print(np.asarray(tMSEset).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(np.asarray(tMSEset).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(G1.state_dict(),\"/home/hjj/Desktop/GANsur2_61_G.pkl\") \n",
    "torch.save(D1.state_dict(),\"/home/hjj/Desktop/GANsur2_61_D.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sample_path=[]\n",
    "sample_path.append('/home/mii/Desktop/cpx222/train/00000')\n",
    "g_in=[]\n",
    "for path2_ in sample_path:\n",
    "    path2_=str(path2_)                \n",
    "        \n",
    "    try:\n",
    "        tomgS=tomgStructure(path2_)\n",
    "            #print(tomgS)\n",
    "        gin=GANs_Gmat(tomgS)\n",
    "                \n",
    "            #print(gin)\n",
    "    except:\n",
    "        pass\n",
    "    g_in.append(gin)\n",
    "       \n",
    "g_in=np.asarray(g_in)\n",
    "g_in=g_in[np.newaxis,:,:,:] \n",
    "g_in=np.asarray(g_in,dtype=np.float64) \n",
    "g_in=Variable(torch.from_numpy(g_in),requires_grad=True)\n",
    "    \n",
    "Gout=G1(g_in)\n",
    "        \n",
    "        #print(Gout.shape)\n",
    "    \n",
    "G_data=round(inverse_transform(Gout.data.numpy().mean()),6)\n",
    "print('G_predict',G_data)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensroflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
